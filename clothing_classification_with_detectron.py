# -*- coding: utf-8 -*-
"""clothing_classification_with_detectron.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jTsqmgWbmXHXdyDZeEED6ChvnJylwttj
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import os

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F

import torchvision
import torchvision.transforms as transforms

from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils

import ast
import cv2

from sklearn import model_selection
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle

import matplotlib.pyplot as plt
# %matplotlib inline

# Don't Show Warning Messages
import warnings
warnings.filterwarnings('ignore')

# Note: Pytorch uses a channels-first format:
# [batch_size, num_channels, height, width]

print(torch.__version__)
print(torchvision.__version__)

!pip install torch

# Commented out IPython magic to ensure Python compatibility.
#@title Install detectron2
# %cd /content/
# install detectron2:
!git clone https://github.com/facebookresearch/detectron2
# %cd /content/detectron2
!pip install -r requirements.txt
!python setup.py install
!pip install git+https://github.com/facebookresearch/fvcore.git

# Set the seed values

import random

seed_val = 101

os.environ['PYTHONHASHSEED'] = str(seed_val)
random.seed(seed_val)
np.random.seed(seed_val)
torch.manual_seed(seed_val)
torch.cuda.manual_seed_all(seed_val)
torch.backends.cudnn.deterministic = True

!python -m pip install pyyaml==5.1
# Detectron2 has not released pre-built binaries for the latest pytorch (https://github.com/facebookresearch/detectron2/issues/4053)
# so we install from source instead. This takes a few minutes.
!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'

import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg

from detectron2.engine import DefaultTrainer
from detectron2.engine import DefaultPredictor
from detectron2.data import DatasetCatalog
from detectron2.data import MetadataCatalog

from detectron2.utils.visualizer import Visualizer
from detectron2.structures import BoxMode
from detectron2.utils.visualizer import ColorMode

import matplotlib.pyplot as plt
import cv2
import random

from google.colab import drive
drive.mount('/content/drive')

"""# Data + Preprocessing"""

import zipfile
import os

zip_path = '/content/drive/My Drive/img.zip'
extract_path = '/content/unzipped_images/'

# unzip the data
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

"""Split the data into 20% for testing and 80% foro training"""

import json
import pandas as pd
from sklearn.model_selection import train_test_split
import os


data = pd.read_csv('/content/10k_int.csv')
train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)

train_data

val_data

val_data.groupby(['category_label']).count()

train_data.groupby(['category_label']).count()

"""# Register Dataset in COCO format"""

def register(df):
    image_root = '/content/unzipped_images'

    # Convert CSV to Detectron2 format
    dataset_dicts = []
    for idx, row in df.iterrows():
        record = {}

        # Image details
        img_path = os.path.join(image_root, row['image_name'])
        # Check if the image file exists
        if not os.path.exists(img_path):
            #print(f"Warning: Image file '{img_path}' does not exist. Skipping.")
            continue
        #print(f"Warning: Image file '{img_path}' exists. NOT SKIPPING.")  # This line added
        height, width = cv2.imread(img_path).shape[:2]
        record['file_name'] = img_path
        record['height'] = height
        record['width'] = width
        record['image_id'] = img_path

        # Annotations
        objs = []
        category_id = row['category_label']
        obj = {
            'bbox': [row['x_1'], row['y_1'], row['x_2'], row['y_2']],
            'bbox_mode': 0,  # Detectron2 uses XYXY_ABS format
            'category_id': category_id,
            'iscrowd': 0
        }
        objs.append(obj)
        record['annotations'] = objs

        dataset_dicts.append(record)

    # Save as JSON

    return dataset_dicts

train_dict = register(train_data)

val_dict = register(val_data)

classes = ["Dress", "Top", "Blouse", "Trousers", "Shorts", "Skirt", "Pullover", "Jacket", "Jumpsuit", "Coverup"]

DatasetCatalog.register("train_dataset2", lambda: register(train_data))
DatasetCatalog.register("val_dataset2", lambda: register(val_data))

MetadataCatalog.get("train_dataset2").thing_classes=classes
MetadataCatalog.get("val_dataset2").thing_classes=classes

# Check that the data registration process worked

train_metadata = MetadataCatalog.get("train_dataset2")

i = 4
d = train_dict[i]

fname = d['file_name'].split('/')[1]
print(fname)

image = cv2.imread(d['file_name'])

visualizer = Visualizer(image[:, :, ::-1], metadata=train_metadata, scale=0.5)
out = visualizer.draw_dataset_dict(d)
plt.imshow(out.get_image()[:, :, ::-1])

# Create a config object.
cfg = get_cfg()

# Change the config
cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("train_dataset2",)
cfg.DATASETS.TEST = ()   # Not using the validation data during training.
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml")
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.0025
cfg.SOLVER.MAX_ITER = 2000
cfg.SOLVER.STEPS = []
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10

# Uncomment this line to see all fields in the config.
# print(cfg)

# Trainer
os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)
trainer = DefaultTrainer(cfg)
trainer.resume_or_load(resume = False)
trainer.train()

# Change the config
cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4  # set the testing threshold for this model
cfg.DATASETS.TEST = ("val_dataset2", )

# Create a predictor
predictor = DefaultPredictor(cfg)

# Get the metadata
val_metadata = MetadataCatalog.get("val_dataset2")

# Get an image to predict on.
# Change this number to select a different image from the val set.
i = 0

d = val_dict[i]
im = cv2.imread(d["file_name"])

# make a prediction
outputs = predictor(im)

outputs

# Visulaize the predicted bounding boxes

# Keep scale=1 in order to associate the predicted coords with the image below.
# If the scale is different the predicted coords won't match the bbox shown on
# the image below.
v = Visualizer(im[:, :, ::-1], metadata=val_metadata, scale=1)
v = v.draw_instance_predictions(outputs["instances"].to("cpu"))


plt.figure(figsize = (14, 10))
plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))
plt.show()

class MyTrainer(DefaultTrainer):
  @classmethod
  def build_evaluator(cls, cfg, dataset_name, output_folder=None):
      if output_folder is None:
         output_folder = os.path.join(cfg.OUTPUT_DIR,"inference")
      return COCOEvaluator(dataset_name, cfg, True, output_folder)

from detectron2.utils.visualizer import ColorMode

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4
cfg.DATASETS.TEST = ("val_dataset2", )
predictor = DefaultPredictor(cfg)


dataset_dicts = val_dict
for d in random.sample(dataset_dicts, 3):
    im = cv2.imread(d["file_name"])
    outputs = predictor(im)
    v = Visualizer(im[:, :, ::-1],
                   metadata=val_metadata,
                   scale=0.8,
                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels
    )
    v = v.draw_instance_predictions(outputs["instances"].to("cpu"))
    plt.figure(figsize = (5, 5))
    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))
    plt.show()

"""# Evaluating the model"""

from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader
evaluator = COCOEvaluator("val_dataset2", output_dir="./output")
val_loader = build_detection_test_loader(cfg, "val_dataset2")
print(inference_on_dataset(predictor.model, val_loader, evaluator))
# another equivalent way to evaluate the model is to use `trainer.test`

from google.colab.patches import cv2_imshow

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "/content/output/model_final.pth")  # path to the model we just trained
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.2   # set a custom testing threshold
predictor = DefaultPredictor(cfg)

img = cv2.imread("/content/drive/MyDrive/content/nicolai.jpeg")
outputs = predictor(img)

pred_classes = outputs["instances"].to("cpu").pred_classes
print (pred_classes)
# Visualize the image with predictions
visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get("train_dataset2"), scale=0.5)
v = visualizer.draw_instance_predictions(outputs["instances"].to("cpu"))
cv2_imshow(v.get_image()[:, :, ::-1])

img = cv2.imread("/content/drive/MyDrive/content/jeans.jpeg")
outputs = predictor(img)

pred_classes = outputs["instances"].to("cpu").pred_classes
print (pred_classes)
# Visualize the image with predictions
visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get("val_dataset2"), scale=0.5)
v = visualizer.draw_instance_predictions(outputs["instances"].to("cpu"))
cv2_imshow(v.get_image()[:, :, ::-1])





img = cv2.imread("/content/drive/MyDrive/content/sonorahands.jpeg")
outputs = predictor(img)

pred_classes = outputs["instances"].to("cpu").pred_classes
print (pred_classes)
# Visualize the image with predictions
visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get("train_dataset2"), scale=0.5)
v = visualizer.draw_instance_predictions(outputs["instances"].to("cpu"))
cv2_imshow(v.get_image()[:, :, ::-1])

cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4
predictor = DefaultPredictor(cfg)
img = cv2.imread("/content/drive/MyDrive/content/gema.jpeg")
outputs = predictor(img)

pred_classes = outputs["instances"].to("cpu").pred_classes
print (pred_classes)
# Visualize the image with predictions
visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get("train_dataset2"), scale=0.5)
v = visualizer.draw_instance_predictions(outputs["instances"].to("cpu"))
cv2_imshow(v.get_image()[:, :, ::-1])

cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3
predictor = DefaultPredictor(cfg)
img = cv2.imread("/content/drive/MyDrive/content/trystan.jpeg")
outputs = predictor(img)

pred_classes = outputs["instances"].to("cpu").pred_classes
print (pred_classes)
# Visualize the image with predictions
visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get("train_dataset2"), scale=0.5)
v = visualizer.draw_instance_predictions(outputs["instances"].to("cpu"))
cv2_imshow(v.get_image()[:, :, ::-1])

cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3
predictor = DefaultPredictor(cfg)
img = cv2.imread("/content/drive/MyDrive/content/guy.jpeg")
outputs = predictor(img)

pred_classes = outputs["instances"].to("cpu").pred_classes
print (pred_classes)
# Visualize the image with predictions
visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get("train_dataset2"), scale=0.5)
v = visualizer.draw_instance_predictions(outputs["instances"].to("cpu"))
cv2_imshow(v.get_image()[:, :, ::-1])

cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3
predictor = DefaultPredictor(cfg)
img = cv2.imread("/content/drive/MyDrive/content/ulrich.jpeg")
outputs = predictor(img)

pred_classes = outputs["instances"].to("cpu").pred_classes
print (pred_classes)
# Visualize the image with predictions
visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get("train_dataset2"), scale=0.5)
v = visualizer.draw_instance_predictions(outputs["instances"].to("cpu"))
cv2_imshow(v.get_image()[:, :, ::-1])

cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4
predictor = DefaultPredictor(cfg)
img = cv2.imread("/content/drive/MyDrive/content/michelle.jpeg")
outputs = predictor(img)

pred_classes = outputs["instances"].to("cpu").pred_classes
print (pred_classes)
# Visualize the image with predictions
visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get("train_dataset2"), scale=0.5)
v = visualizer.draw_instance_predictions(outputs["instances"].to("cpu"))
cv2_imshow(v.get_image()[:, :, ::-1])